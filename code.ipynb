{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31198722-117f-46b6-b0b9-2143e3fb7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "from torch import Tensor\n",
    "from scipy.special import gamma \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad835898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated()/ (1024*1024)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2445c1-dc22-406f-b3af-781cdf923080",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737e273-f881-4a01-b699-e73c3661a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1335b-5793-4440-8f58-932c34be8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fractional_Order_Matrix_Differential_Solver(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,input1,w,b,alpha):\n",
    "        alpha = torch.tensor(alpha)\n",
    "        ctx.save_for_backward(input1,w,b,alpha)\n",
    "        outputs = input1@w + b\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        input1,w,b,alpha = ctx.saved_tensors\n",
    "        x_fractional, w_fractional = Fractional_Order_Matrix_Differential_Solver.Fractional_Order_Matrix_Differential_Linear(input1,w,b,alpha)   \n",
    "        x_grad = torch.mm(grad_outputs,x_fractional)\n",
    "        w_grad = torch.mm(w_fractional,grad_outputs)\n",
    "        b_grad = grad_outputs.sum(dim=0)\n",
    "        return x_grad, w_grad, b_grad,None\n",
    "\n",
    "    @staticmethod\n",
    "    def Fractional_Order_Matrix_Differential_Linear(x,w,b,alpha):\n",
    "        #w\n",
    "        wf = w[:,0].view(1,-1)\n",
    "        #main\n",
    "        w_main = torch.mul(x,torch.abs(wf)**(1-alpha)/gamma(2-alpha))\n",
    "        #partial\n",
    "        x_rows, x_cols = x.size()\n",
    "        bias = torch.full((x_rows, x_cols),b[0].item())\n",
    "        bias = bias.to(device)\n",
    "        w_partial = torch.mul(torch.mm(x,wf.T).view(-1,1).expand(-1,x_cols) - torch.mul(x,wf) + bias, torch.sign(wf)*torch.abs(wf)**(-alpha)/gamma(1-alpha))\n",
    "        return w.T, (w_main + w_partial).T\n",
    "\n",
    "class FLinear(nn.Module):\n",
    "    \n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, alpha=0.9, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.weight = Parameter(torch.empty((in_features, out_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return Fractional_Order_Matrix_Differential_Solver.apply(x, self.weight, self.bias, self.alpha)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a7873-7621-45ea-aa8e-cf0b142f452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X,y):\n",
    "    X_train,X_temp,y_train,y_temp = train_test_split(X,y,test_size=0.3,shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.333,shuffle=False)\n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d741f91-1b61-43b5-9f8d-ddb78a458ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_windows_size = 36  #i.e.,input length\n",
    "pred_length = 48     #i.e.,prediction lengths,48,96,192,384\n",
    "stock = 'ETTh1'\n",
    "df_DJIA = pd.read_csv(r'./data/'+stock+'.csv')\n",
    "#del df_DJIA['Date']       #DJI\n",
    "del df_DJIA['date']        #ETT\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "sca_DJIA = scaler.fit_transform(df_DJIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c5305-330f-4abf-a40e-7c4555f66296",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_j = 6     # DJI is 4, and ETTh1 is 6.\n",
    "def create_sequences(data, slide_windows_size, pred_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - slide_windows_size - pred_length + 1):\n",
    "        X.append(data[i:i+slide_windows_size, :])  # sliding window size [seq_len, features]\n",
    "        y.append(data[i+slide_windows_size:i+slide_windows_size+pred_length, features_j])  \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(sca_DJIA, slide_windows_size, pred_length)\n",
    "X = torch.Tensor(X).to(device)\n",
    "y = torch.Tensor(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81c094-3a01-40ab-abd1-086e14bb6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Square Error\n",
    "def MSE(pred,true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "#Mean Absolute Error\n",
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred-true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2f960-2bfe-43c1-8f72-73836650b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = split(X,y)   #7:2:1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc7f4a-1a8e-4d87-b2de-2c716baa7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "set_seed()\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, output_size=pred_length):   ###DJI:hidden_size=256,ETTh1:hidden_size=128.\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = FLinear(input_size, hidden_size, alpha)       \n",
    "        #self.linear1 = nn.Linear(input_size, hidden_size)                                  #To calculate the Memory usage on SGD.\n",
    "        self.linear2 = FLinear(hidden_size, output_size, alpha)      \n",
    "        #self.linear2 = nn.Linear(hidden_size, output_size)                                 #To calculate the Memory usage on SGD.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # (batch_size, seq_len*num_features)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe6e05-64b4-4e99-b75d-0dda47ee771a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = 1.0   ####0.7,0.8,0.9,1.0\n",
    "num_feature = 7      # DJI is 5, and ETTh1 is 7.\n",
    "\n",
    "set_seed()\n",
    "model = MLP(input_size=slide_windows_size*num_feature).to(device)\n",
    "\n",
    "train_loss10 = []    ###\n",
    "val_loss10 = []      ###\n",
    "\n",
    "lr =1e-4   \n",
    "num_epochs = 1500   #1500\n",
    "best_loss = 10\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "#time_start = time.time()\n",
    "#initial_allocated = get_memory_usage()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss_sum += loss\n",
    "        #loss.backward(retain_graph=True)     #The default value of retain_graph is False. only for the first time, to calculate the Memory usage.\n",
    "        loss.backward()   #The default value of retain_graph is False.\n",
    "        optimizer.step()\n",
    "    final_allocated = get_memory_usage() \n",
    "    time_end = time.time()\n",
    "    #print(f\"Final allocated memory: {(final_allocated-initial_allocated):.4f} MB\")   \n",
    "    #print(f\"Training time: {(time_end-time_start):.4f}s\")\n",
    "    train_loss10.append(loss_sum.cpu().detach().numpy())     ###########\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss_sum.cpu().detach().numpy():.4f}\")\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Val_outputs = model(X_val)\n",
    "        MSE_val = MSE(y_val.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "        \n",
    "        val_loss10.append(MSE_val)   ########################Validation_loss\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Val Loss: {MSE_val:.4f}\")\n",
    "        print('')\n",
    "        if best_loss > MSE_val:\n",
    "            best_loss = MSE_val\n",
    "            #torch.save(model.state_dict(), r'./model/'+stock+'_model_fractional_'+str(alpha).replace(\".\", \"_\")+'_'+str(pred_length)+'.pth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae9d0c-a808-468e-937a-19c59c1e1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3),dpi=1200)\n",
    "plt.plot(train_loss07,c='k',label=r'$\\alpha=0.7$')\n",
    "plt.plot(train_loss08,c='y',label=r'$\\alpha=0.8$')\n",
    "plt.plot(train_loss09,c='b',label=r'$\\alpha=0.9$')\n",
    "plt.plot(train_loss10,c='r',label=r'$\\alpha=1.0$')\n",
    "plt.xlim(0,1500)\n",
    "plt.ylim(0.7,2)\n",
    "plt.xlabel('$Epochs$')\n",
    "plt.ylabel('$Loss$')\n",
    "plt.legend()\n",
    "#plt.savefig('picture/fig4_c.png',bbox_inches='tight',format='png')\n",
    "#plt.savefig('picture/fig4_c.svg',bbox_inches='tight',format='svg')\n",
    "#plt.savefig('picture/fig4_c.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c95beb-41a3-44f9-bbff-cf6ada27bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3),dpi=1200)\n",
    "plt.plot(val_loss07,c='k',label=r'$\\alpha=0.7$')\n",
    "plt.plot(val_loss08,c='y',label=r'$\\alpha=0.8$')\n",
    "plt.plot(val_loss09,c='b',label=r'$\\alpha=0.9$')\n",
    "plt.plot(val_loss10,c='r',label=r'$\\alpha=1.0$')\n",
    "plt.xlim(0,1500)\n",
    "plt.ylim(0.02,0.1)\n",
    "plt.xlabel('$Epochs$')\n",
    "plt.ylabel('$Loss$')\n",
    "plt.legend()\n",
    "#plt.savefig('picture/fig4_d.png',bbox_inches='tight',format='png')\n",
    "#plt.savefig('picture/fig4_d.svg',bbox_inches='tight',format='svg')\n",
    "#plt.savefig('picture/fig4_d.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b6e1d-9ced-44de-967f-5a853848d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/'+stock+'_model_fractional_1_0_48.pth'))  ##\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "MSE10 = MSE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "MAE10 = MAE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "print('MSE:',MSE10)\n",
    "print('MAE:',MAE10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120b398-a30f-4b60-aa87-77696407997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/'+stock+'_model_fractional_0_9_48.pth'))  ##\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "MSE09 = MSE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "MAE09 = MAE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "print('MSE:',MSE09)\n",
    "print('MAE:',MAE09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7aed9-412a-4975-b74e-f9b0c441f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/'+stock+'_model_fractional_0_8_48.pth'))  ##\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "MSE08 = MSE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "MAE08 = MAE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "print('MSE:',MSE08)\n",
    "print('MAE:',MAE08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ef1a4-5ed3-45f5-833a-9a1553d8ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/'+stock+'_model_fractional_0_7_48.pth'))  ##\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "MSE07 = MSE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "MAE07 = MAE(y_test.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "print('MSE:',MSE07)\n",
    "print('MAE:',MAE07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb4dab-8e7d-4dd5-bc73-ce0701fb2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_ETTh1 = [0.022396602, 0.022331236, 0.018228948, 0.030933399]    ####MSE_DJI,MAE_DJI\n",
    "MAE_ETTh1 = [0.11748641, 0.11968101, 0.10541517, 0.13710967]\n",
    "x = [0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa17c0f-e37b-4e94-9e13-117908166b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3),dpi=1200)\n",
    "\n",
    "plt.plot(x,MSE_ETTh1,'o-',c='r',label=r'MSE')\n",
    "plt.plot(x,MAE_ETTh1,'o-',c='b',label=r'MAE')\n",
    "\n",
    "plt.text(0.71, 0.032396602, f'0.0224', ha='center')\n",
    "plt.text(0.8, 0.032331236, f'0.0223', ha='center')\n",
    "plt.text(0.9, 0.028228948, f'0.0182', ha='center')\n",
    "plt.text(0.99, 0.040933399, f'0.0309', ha='center')\n",
    "\n",
    "plt.text(0.71, 0.12748641, f'0.1175', ha='center')\n",
    "plt.text(0.81, 0.12568101, f'0.1197', ha='center')\n",
    "plt.text(0.9, 0.11541517, f'0.1054', ha='center')\n",
    "plt.text(0.99, 0.12010967, f'0.1371', ha='center')\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.ylabel('$Metrics$')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.legend()\n",
    "#plt.savefig('picture/Fig5_b.png',bbox_inches='tight',format='png')\n",
    "#plt.savefig('picture/Fig5_b.svg',bbox_inches='tight',format='svg')\n",
    "#plt.savefig('picture/Fig5_b.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_12_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
